import torch
import numpy as np
from minichess_env import MiniChessEnv

# 1. å¯¼å…¥ä½ çš„ Agent ç±»
# æ³¨æ„ï¼šä½ çš„æˆªå›¾é‡Œæ–‡ä»¶åæ˜¯ my_agent2.pyï¼Œç±»åæ˜¯ Agent2
from my_agent2 import Agent2 

# ================= é…ç½®åŒºåŸŸ =================
# åœ¨è¿™é‡Œå¡«å…¥ä½ æƒ³å¯¹æ¯”çš„ä¸¤ä¸ªæ¨¡å‹è·¯å¾„
MODEL_PATH_B = '100_best_model.pth'  # æ‰®æ¼” Gold (å…ˆæ‰‹)
MODEL_PATH_A = 'submit_best_model.pth'  # æ‰®æ¼” Silver (åæ‰‹)
# ===========================================

def get_agent_with_weights(pth_path):
    """å®ä¾‹åŒ– Agent å¹¶å¼ºåˆ¶åŠ è½½æŒ‡å®šçš„æƒé‡æ–‡ä»¶"""
    print(f"æ­£åœ¨åˆå§‹åŒ– Agent å¹¶åŠ è½½: {pth_path} ...")
    
    agent = Agent2()
    
    # 2. å¼ºåˆ¶è¦†ç›–æƒé‡
    # map_location='cuda:0' æˆ– 'cpu' å–å†³äºä½ çš„ç¯å¢ƒï¼Œè¿™é‡Œè®¾ä¸ºè‡ªåŠ¨
    device = agent.device 
    state_dict = torch.load(pth_path, map_location=device)
    
    # 3. è½½å…¥æ–°æƒé‡
    agent.model.load_state_dict(state_dict)
    agent.model.eval() # ç¡®ä¿è¿›å…¥è¯„ä¼°æ¨¡å¼
    
    return agent

def play_match(agent_gold, agent_silver):
    env = MiniChessEnv()
    obs, _ = env.reset()
    
    # 1 ä»£è¡¨ Gold (å…ˆæ‰‹), -1 ä»£è¡¨ Silver (åæ‰‹)
    players = {1: agent_gold, -1: agent_silver}
    current_player = 1 # Gold å…ˆæ‰‹
    max_turns = 1000
    
    print(f"\nğŸ”¥ å¯¹å±€å¼€å§‹: {MODEL_PATH_A} (Gold) VS {MODEL_PATH_B} (Silver)")
    
    for turn in range(max_turns):
        legal_moves = env.get_legal_moves()
        if not legal_moves:
            winner = -current_player
            print(f"ç»“æœ: {'Gold' if current_player==1 else 'Silver'} æ— è·¯å¯èµ°ï¼Œåˆ¤è´Ÿã€‚")
            return winner

        # è·å–å½“å‰ç©å®¶çš„ Agent
        active_agent = players[current_player]
        
        # è·å–åŠ¨ä½œ
        # æ³¨æ„ï¼šè¿™é‡Œä¼ å…¥ env.board.copy() ä»¥é˜² Agent ä¿®æ”¹åŸå§‹æ£‹ç›˜
        action = active_agent.get_action(env.board.copy(), current_player)
        
        if action not in legal_moves:
            print(f"éæ³•åŠ¨ä½œ! ç©å®¶ {current_player} å°è¯•äº† {action}")
            return -current_player
            
        env.step(action)
        
        # å¯é€‰ï¼šæ‰“å°æ¯ä¸€æ­¥ï¼ˆå¦‚æœå«Œå¤ªé•¿å¯ä»¥æ³¨é‡Šæ‰ï¼‰
        # env.render() 
        
        current_player *= -1
        
    print("ç»“æœ: å¹³å±€ (è¾¾åˆ°æœ€å¤§å›åˆæ•°)")
    return 0

if __name__ == "__main__":
    # 1. åŠ è½½ä¸¤ä¸ªä¸åŒæƒé‡çš„ Agent
    try:
        player_a = get_agent_with_weights(MODEL_PATH_A)
        player_b = get_agent_with_weights(MODEL_PATH_B)
        
        # 2. å¼€å§‹å¯¹æˆ˜
        winner = play_match(player_a, player_b)
        
        print("-" * 30)
        if winner == 1:
            print(f"ğŸ† æœ€ç»ˆè·èƒœ: Gold ({MODEL_PATH_A})")
        elif winner == -1:
            print(f"ğŸ† æœ€ç»ˆè·èƒœ: Silver ({MODEL_PATH_B})")
        else:
            print("ğŸ¤ æœ€ç»ˆç»“æœ: å¹³å±€")
            
        print("-" * 30)

        
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„åç§°ã€‚\n{e}")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")